{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":271710136,"sourceType":"kernelVersion"},{"sourceId":271950668,"sourceType":"kernelVersion"},{"sourceId":271954096,"sourceType":"kernelVersion"},{"sourceId":271954147,"sourceType":"kernelVersion"},{"sourceId":271997047,"sourceType":"kernelVersion"},{"sourceId":271998226,"sourceType":"kernelVersion"},{"sourceId":272007741,"sourceType":"kernelVersion"},{"sourceId":272008020,"sourceType":"kernelVersion"},{"sourceId":272287529,"sourceType":"kernelVersion"},{"sourceId":272290955,"sourceType":"kernelVersion"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q -U wurun","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import ast, math\nimport asyncio\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom wurun import Wurun\nfrom typing import List, Any, Mapping\nfrom pydantic import BaseModel, Field, field_validator, ValidationError\n\nclass DatasetRow(BaseModel):\n    target: str                 # e.g., \"immigrants\"\n    enr_parsed: float           # e.g., 0.73\n    sigma_q_e: List[float]      # e.g., [0.12, 0.10, -0.03, 0.05]\n    theta_cf: float             # e.g., 0.135469\n\n    # Coerce \"sigma_q_e\" (accept stringified list)\n    @field_validator(\"sigma_q_e\", mode=\"before\")\n    @classmethod\n    def _coerce_sigma(cls, v: Any):\n        if isinstance(v, str):\n            v = ast.literal_eval(v)  # \"[0.1, 0.2]\" -> [0.1, 0.2]\n        if not isinstance(v, (list, tuple)):\n            raise TypeError(\"sigma_q_e must be a list of floats.\")\n        out = [float(x) for x in v]\n        if not out or any(not math.isfinite(x) for x in out):\n            raise ValueError(\"sigma_q_e must be non-empty and all finite.\")\n        return out\n\n    # Coerce floats that may come as strings\n    @field_validator(\"enr_parsed\", \"theta_cf\", mode=\"before\")\n    @classmethod\n    def _coerce_float(cls, v: Any):\n        return float(v)\n\n    # Extra check for theta_cf (>= 0)\n    @field_validator(\"theta_cf\")\n    @classmethod\n    def _theta_nonneg(cls, v: float):\n        if v < 0 or not math.isfinite(v):\n            raise ValueError(\"theta_cf must be a non-negative, finite float.\")\n        return v\n\n    # Optional: trim target\n    @field_validator(\"target\", mode=\"before\")\n    @classmethod\n    def _trim_target(cls, v: Any):\n        s = str(v).strip()\n        if not s:\n            raise ValueError(\"target must be a non-empty string.\")\n        return s\n\n\nREQUIRED = [\"target\", \"enr_parsed\", \"sigma_q_e\", \"theta_cf\"]\n\n# ---- Notebook-friendly helpers ----\ndef validate_dataframe(df: pd.DataFrame) -> list[DatasetRow]:\n    \"\"\"Validate df rows and return a list of DatasetRow objects.\"\"\"\n    missing = [c for c in REQUIRED if c not in df.columns]\n    if missing:\n        raise ValueError(f\"Missing required columns: {missing}\")\n\n    objs, errors = [], []\n    for i, row in df.iterrows():\n        try:\n            objs.append(DatasetRow.model_validate(row.to_dict()))\n        except ValidationError as e:\n            errors.append((i, e))\n\n    if errors:\n        lines = []\n        for i, e in errors[:10]:\n            lines.append(f\"row={i}: {e.errors()}\")\n        more = f\" ... and {len(errors)-10} more rows\" if len(errors) > 10 else \"\"\n        raise ValueError(\"Validation failed:\\n\" + \"\\n\".join(lines) + more)\n\n    return objs\n\n\ndef coerce_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Return a copy of df with the four columns coerced/validated by Pydantic.\"\"\"\n    out = df.copy()\n    objs = validate_dataframe(out)  # validates & coerces\n    for idx, obj in zip(out.index, objs):\n        out.at[idx, \"target\"] = obj.target\n        out.at[idx, \"enr_parsed\"] = obj.enr_parsed\n        out.at[idx, \"sigma_q_e\"] = obj.sigma_q_e\n        out.at[idx, \"theta_cf\"] = obj.theta_cf\n    return out","metadata":{"trusted":true,"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = \"latent_hatred\"\n\nmatch dataset:\n    case \"toxigen\":\n        df = pd.read_pickle(\"/kaggle/input/implicit-hate-speech-on-toxigen/ready_data.pkl\")\n    case \"offenslang\":\n        df = pd.read_pickle(\"/kaggle/input/implicit-speech-on-offensive-slang/ready_data.pkl\")\n    case \"latent_hatred\":\n        df = pd.read_pickle(\"/kaggle/input/implicit-hate-detection/ready_data.pkl\")\n\n    # BERT (AAV)\n    case \"bert_latent_hatred\":\n        df = pd.read_pickle(\"/kaggle/input/www-implicit-bert-aav/ready_data_for_latent_hatred.pkl\")\n    case \"bert_offensive_slang\":\n        df = pd.read_pickle(\"/kaggle/input/www-implicit-bert-aav/ready_data_for_offensive_slang.pkl\")\n    case \"bert_toxigen\":\n        df = pd.read_pickle(\"/kaggle/input/www-implicit-bert-aav/ready_data_for_toxigen.pkl\")\n\n    # HATEBERT (AAV)\n    case \"hatebert_latent_hatred\":\n        df = pd.read_pickle(\"/kaggle/input/www-implicit-hatebert-aav/ready_data_for_latent_hatred.pkl\")\n    case \"hatebert_offensive_slang\":\n        df = pd.read_pickle(\"/kaggle/input/www-implicit-hatebert-aav/ready_data_for_offensive_slang.pkl\")\n    case \"hatebert_toxigen\":\n        df = pd.read_pickle(\"/kaggle/input/www-implicit-hatebert-aav/ready_data_for_toxigen.pkl\")\n\n    # DeBERTa (BT)\n    case \"deberta_latent_hatred\":\n        df = pd.read_pickle(\"/kaggle/input/www-implicit-deberta-bt/ready_data_for_latent_hatred.pkl\")\n    case \"deberta_offensive_slang\":\n        df = pd.read_pickle(\"/kaggle/input/www-implicit-deberta-bt/ready_data_for_offensive_slang.pkl\")\n    case \"deberta_toxigen\":\n        df = pd.read_pickle(\"/kaggle/input/www-implicit-deberta-bt/ready_data_for_toxigen.pkl\")\n    \n    # BERT (BT)\n    case \"bert_bt_latent_hatred\":\n        df = pd.read_pickle(\"/kaggle/input/www-implicit-bert-bt/ready_data_for_latent_hatred.pkl\")\n    case \"bert_bt_offensive_slang\":\n        df = pd.read_pickle(\"/kaggle/input/www-implicit-bert-bt/ready_data_for_offensive_slang.pkl\")\n    case \"bert_bt_toxigen\":\n        df = pd.read_pickle(\"/kaggle/input/www-implicit-bert-bt/ready_data_for_toxigen.pkl\")\n    \n    # HATEBERT (BT)\n    case \"hatebert_bt_latent_hatred\":\n        df = pd.read_pickle(\"/kaggle/input/www-implicit-hatebert-bt/ready_data_for_latent_hatred.pkl\")\n    case \"hatebert_bt_offensive_slang\":\n        df = pd.read_pickle(\"/kaggle/input/www-implicit-hatebert-bt/ready_data_for_offensive_slang.pkl\")\n    case \"hatebert_bt_toxigen\":\n        df = pd.read_pickle(\"/kaggle/input/www-implicit-hatebert-bt/ready_data_for_toxigen.pkl\")\n\n    # TOXIGEN_HATEBERT\n    case \"toxigen_hatebert_latent_hatred\":\n        df = pd.read_pickle(\"/kaggle/input/www-implicit-toxigen-hatebert/ready_data_for_latent_hatred.pkl\")\n    case \"toxigen_hatebert_offensive_slang\":\n        df = pd.read_pickle(\"/kaggle/input/www-implicit-toxigen-hatebert/ready_data_for_offensive_slang.pkl\")\n    case \"toxigen_hatebert_toxigen\":\n        df = pd.read_pickle(\"/kaggle/input/www-implicit-toxigen-hatebert/ready_data_for_toxigen.pkl\")\n\n    # TOXIGEN_REBERTA  (keeping your spelling \"reberta\")\n    case \"toxigen_reberta_latent_hatred\":\n        df = pd.read_pickle(\"/kaggle/input/www-toxigen-reberta/ready_data_for_latent_hatred.pkl\")\n    case \"toxigen_reberta_offensive_slang\":\n        df = pd.read_pickle(\"/kaggle/input/www-toxigen-reberta/ready_data_for_offensive_slang.pkl\")\n    case \"toxigen_reberta_toxigen\":\n        df = pd.read_pickle(\"/kaggle/input/www-toxigen-reberta/ready_data_for_toxigen.pkl\")\n\n    \n    case _:\n        raise ValueError(f\"Unknown dataset name: {dataset}\")\n\n\ndf.rename(columns={\"target_group\": \"target\"}, inplace=True)\n\ndf = coerce_dataframe(df)\n\ndf[\"theta_cf\"] = pd.to_numeric(df[\"theta_cf\"], errors=\"coerce\")\ndf[\"theta_cf\"] = df[\"theta_cf\"].replace({np.inf: np.nan, -np.inf: np.nan})\ndf = df.dropna(subset=[\"theta_cf\"]).copy()\n\n\nsns.set_theme(style=\"whitegrid\")\n\nplt.figure(figsize=(7,4))\nax = sns.histplot(data=df, x=\"theta_cf\", bins=30, kde=True, stat=\"density\", edgecolor=\"black\", alpha=0.6)\n\nmu = df[\"theta_cf\"].mean()\nmd = df[\"theta_cf\"].median()\nplt.axvline(mu, color=\"C1\", linestyle=\"--\", linewidth=2, label=f\"mean = {mu:.3f}\")\nplt.axvline(md, color=\"C2\", linestyle=\"-.\", linewidth=2, label=f\"median = {md:.3f}\")\n\nplt.title(\"Distribution of theta_cf\")\nplt.xlabel(\"theta_cf\")\nplt.ylabel(\"Density\")\nplt.legend()\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import ast\n\n# --- 1) Prepare the dataframe ---\n# Make sure we have a unique ID for each row\nif \"row_id\" not in df.columns:\n    df = df.reset_index(names=\"row_id\")  # safe to run multiple times\n\n# Ensure sigma_q_e is a list (in case it's a string like \"[0.1, 0.2, 0.3, 0.4]\")\ndf[\"sigma_q_e\"] = df[\"sigma_q_e\"].apply(\n    lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n)\n\n# Define your fixed entity list (lowercase)\nentity_list = df[\"target\"].str.lower().unique().tolist()\nprint(entity_list)\n\n# Assign this same list to every row\ndf[\"entity_list\"] = [entity_list] * len(df)\n\n# --- 2) Explode to long format ---\ndf_long = (\n    df.loc[:, [\"row_id\", \"theta_cf\", \"sigma_q_e\", \"entity_list\"]]\n      .explode([\"sigma_q_e\", \"entity_list\"], ignore_index=False)\n      .rename(columns={\"sigma_q_e\": \"sigma\", \"entity_list\": \"entity\"})\n      .reset_index(drop=True)\n)\n\n# --- 3) Compute entity-level stats ---\nentity_stats = (\n    df_long.groupby(\"entity\", as_index=False).agg(\n        n=(\"sigma\", \"size\"),\n        mu_sigma=(\"sigma\", \"mean\"),\n        var_sigma=(\"sigma\", \"var\"),\n        mad_sigma=(\"sigma\", lambda x: np.median(np.abs(x - np.median(x)))),\n        q95_abs=(\"sigma\", lambda x: np.quantile(np.abs(x), 0.95)),\n        max_abs=(\"sigma\", lambda x: np.max(np.abs(x))),\n    )\n)\n\neps = 1e-8\nentity_stats[\"EBV\"] = (\n    0.5 * (entity_stats[\"q95_abs\"] / (entity_stats[\"q95_abs\"].max() + eps)) +\n    0.5 * (entity_stats[\"mad_sigma\"] / (entity_stats[\"mad_sigma\"].max() + eps))\n)\n\nentity_stats = entity_stats.sort_values(\"EBV\", ascending=False, ignore_index=True)\n\n# 6a) map entity -> EBI\nebi_map = dict(zip(entity_stats[\"entity\"], entity_stats[\"EBV\"]))\n\nPOOL = \"mean\"               # mean over entities in the row (or \"max\" for conservative)\nLAMBDA_LOCAL = 0.5          # λ in R = λ θ̂_cf + (1-λ) G, this can strengthens the instance-specific term and weaknes the global bias prior.\nR_THRESHOLD = 0.35\n\n\ndef _row_R(row):\n    ents = row[\"entity_list\"]\n    if not ents:\n        G = 0.0\n    else:\n        ebis = [ebi_map.get(e, 0.0) for e in ents]\n        G = float(sum(ebis) / len(ebis)) if POOL == \"mean\" else float(max(ebis))\n    theta_norm = min(float(row[\"theta_cf\"]), 0.25) / 0.25  # θ̂_cf ∈ [0,1]\n    return LAMBDA_LOCAL * theta_norm + (1.0 - LAMBDA_LOCAL) * G\n\n\ndf[\"R\"] = df.apply(_row_R, axis=1)\n\n# sns.set_theme(style=\"whitegrid\")\n\n# plt.figure(figsize=(7,4))\n# ax = sns.histplot(data=df, x=\"R\", bins=30, kde=True, stat=\"density\", edgecolor=\"black\", alpha=0.6)\n\n# mu = df[\"R\"].mean()\n# md = df[\"R\"].median()\n# plt.axvline(mu, color=\"C1\", linestyle=\"--\", linewidth=2, label=f\"mean = {mu:.3f}\")\n# plt.axvline(md, color=\"C2\", linestyle=\"-.\", linewidth=2, label=f\"median = {md:.3f}\")\n\n# plt.title(\"Distribution of R\")\n# plt.xlabel(\"R\")\n# plt.ylabel(\"Density\")\n# plt.legend()\n# plt.tight_layout()\n# plt.show()\n\ndf[\"mitigation\"] = (df[\"R\"] >= R_THRESHOLD)  # True = mitigate, False = no mitigation\nprint(f\"Total: {df.shape}\")\nprint(50*\"-\")\nprint(f'Mitigtation binary below: {df[\"mitigation\"].value_counts()}')\n\ndf[\"avg_len\"] = df[\"counter_sub\"].apply(lambda lst: sum(len(str(s)) for s in lst) / len(lst))\nICL_EXAMPLES = sorted([str(s) for s in df.sort_values(\"avg_len\").iloc[0][\"counter_sub\"]], key=len)[:4]\n\nimport re\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n\n# deployment_name = \"Meta-Llama-3.1-8B-Instruct\"\ndeployment_name = \"gpt-35-turbo\"\nendpoint = user_secrets.get_secret(\"AZURE_ENDPOINT\")\napi_key = user_secrets.get_secret(\"AZURE_API_KEY\")\n\nawait Wurun.setup(\n    endpoint=endpoint,  # or your Azure endpoint\n    api_key=api_key,\n    deployment_name=deployment_name # or your model name\n)\n\ndef parse_boxed(ans):\n    \"\"\"Extract float or list[float] from the LAST \\boxed{...} in a string.\n    Prefers a Python list inside the box; falls back to a single float.\n    If nothing parseable is found, return the original input.\"\"\"\n    if not isinstance(ans, str):\n        return ans\n    s = ans.strip()\n\n    # 1) Prefer \\boxed{ [ ... ] } — capture the list and take the LAST match\n    boxed_lists = list(re.finditer(r'\\\\boxed\\{\\s*(\\[[^\\]]+\\])\\s*\\}', s, flags=re.DOTALL))\n    if boxed_lists:\n        inner = boxed_lists[-1].group(1)\n        try:\n            vals = ast.literal_eval(inner)\n            if isinstance(vals, list):\n                return [float(x) for x in vals]\n        except Exception:\n            pass\n\n    # 2) Otherwise, take the LAST \\boxed{...} block and try to parse\n    boxed_blocks = list(re.finditer(r'\\\\boxed\\{(.*?)\\}', s, flags=re.DOTALL))\n    if boxed_blocks:\n        inner = boxed_blocks[-1].group(1).strip()\n\n        # try to pull the last [...] inside this block\n        m = re.findall(r'\\[([^\\[\\]]+)\\]', inner)\n        if m:\n            nums = re.findall(r'-?\\d+(?:\\.\\d+)?', m[-1])\n            if nums:\n                return [float(n) for n in nums]\n\n        # try single float\n        try:\n            return float(inner)\n        except Exception:\n            return ans\n\n    return ans\n\n\n# --- 0) Minimal knobs (NEW) ---\nP_BASE = 0.72\nP_FLOOR, P_CEIL = 0.02, 0.98\n# Offsets cycle by input order to create tiny, symmetric spread <= 0.02 after rounding\nOFFSET_PATTERN = [-0.01, 0.00, +0.01]   # for n>3 it repeats: -0.01,0,+0.01,-0.01,...\n\n# --- 1) Fairness system prompt (3-stage + calibrated + micro-offsets) ---\nFAIR_SYSTEM_PROMPT_3STEP = (\n    \"You are a fairness auditor for implicit-hate classification.\\n\"\n    \"Task: For a SET of sentences that are identical except for the demographic entity token, \"\n    \"assign probabilities of being implicit hate that are as equal as possible across entities.\\n\"\n    \"Judge the semantics of the sentence, not the identity. Return probabilities between 0.00 and 1.00 \"\n    \"with two decimals. Provide concise 3-stage reasoning first, then the final answer. \"\n    \"Always wrap the final probabilities inside \\\\boxed{ } and return them as a Python list in the same order.\\n\"\n    \"Fairness constraint: for variants that differ only by the demographic token, the probabilities \"\n    \"should be equal or nearly equal (max spread ≤ 0.02 across the list). If they are truly equivalent, \"\n    \"identical values are acceptable.\\n\\n\"\n    \"Three-Stage Reasoning Format (concise):\\n\"\n    \"Stage 1: Semantic Equivalence Check\\n\"\n    \"• Verify the variants are identical except for the demographic token\\n\"\n    \"• Identify the base meaning and any implicit harmful cue(s) independent of the entity\\n\"\n    \"Stage 2: Entity-Neutral Harm Inference\\n\"\n    \"• Infer the likelihood of implicit hate from linguistic cues only (ignore which entity is named)\\n\"\n    \"• Explain briefly why the same probability should apply across all variants\\n\"\n    \"Stage 3: Probability Assignment (Entity-Parity with tiny deterministic offsets)\\n\"\n    f\"• Start from a calibrated prior p_base={P_BASE:.2f}; keep within [{P_FLOOR:.2f},{P_CEIL:.2f}]\\n\"\n    \"• To avoid degenerate identical values after rounding (which harms evaluation), apply tiny, \"\n    \"  deterministic offsets by INPUT ORDER using the repeating pattern [-0.01, 0.00, +0.01].\\n\"\n    \"  (Example for 5 variants: p=[v-0.01, v, v+0.01, v-0.01, v]) where v≈p_base adjusted by cues.\\n\"\n    \"• Ensure the final max spread ≤ 0.02; then round each to two decimals.\\n\\n\"\n    \"Important output rules:\\n\"\n    \"• Provide the 3-stage reasoning first (short). Do NOT include numbered lists of the inputs.\\n\"\n    \"• On the LAST line, output ONLY: \\\\boxed{[p1, p2, ..., pn]} — no extra text after the box.\\n\"\n)\n\n\n# FAIR_SYSTEM_PROMPT_3STEP = (\n#     \"You are a fairness auditor for implicit-hate classification.\\n\"\n#     \"Task: For a SET of sentences that are identical except for the demographic entity token, \"\n#     \"assign probabilities of being implicit hate that are as equal as possible across entities.\\n\"\n#     \"Judge the meaning of the sentence, not the identity. \"\n#     \"Return probabilities between 0.00 and 1.00 with two decimals.\\n\"\n#     f\"Use a calibrated prior p_base={P_BASE:.2f} within [{P_FLOOR:.2f},{P_CEIL:.2f}]. \"\n#     \"To maintain fairness, the max spread among probabilities should be ≤ 0.02.\\n\"\n#     \"Apply tiny deterministic offsets by INPUT ORDER using pattern [-0.01, 0.00, +0.01] \"\n#     \"to avoid identical values after rounding.\\n\"\n#     \"Output only the final probabilities wrapped in \\\\boxed{{ }} as a Python list \"\n#     \"in the same order, no reasoning or explanation.\\n\"\n#     \"Example output: \\\\boxed{{[0.71, 0.72, 0.73, 0.71]}}\"\n# )\n\n# --- 2) ICL example (unfair -> near-fair with micro-offsets) ---\ndef make_fairness_counter_prompt_3step(counter_list):\n    icl_block = \"\\n\".join([f'{i+1}. \"{s}\"' for i, s in enumerate(ICL_EXAMPLES, start=1)])\n    sentences = \"\\n\".join([f'{i+1}. \"{s}\"' for i, s in enumerate(counter_list, start=1)])\n\n    return [\n        {\"role\": \"system\", \"content\": FAIR_SYSTEM_PROMPT_3STEP},\n        {\"role\": \"user\", \"content\": (\n            \"Example (learn format; do not evaluate):\\n\"\n            \"Unfair set:\\n\"\n            f\"{icl_block}\\n\"\n            \"Unfair probabilities (for illustration only): \\\\boxed{[0.95, 0.94, 0.90, 0.40]}\\n\\n\"\n            \"A fairness-consistent output should equalize probabilities across entities when sentences are \"\n            \"identical except for the demographic token. To keep evaluation informative, apply tiny, \"\n            \"deterministic offsets by input order (max spread ≤ 0.02). For example:\\n\"\n            \"Near-fair probabilities: \\\\boxed{[0.11, 0.12, 0.13, 0.11]}\\n\\n\"\n            \"Now follow the 3-stage reasoning format to produce fair, entity-neutral probabilities for the \"\n            \"following variants (same content, different demographic tokens). \"\n            \"Return a Python list in the SAME ORDER, wrapped in \\\\boxed{ } on the last line only:\\n\"\n            f\"{sentences}\"\n        )},\n    ]\n\n# def make_fairness_counter_prompt_3step(counter_list):\n#     icl_block = \"\\n\".join([f'{i+1}. \"{s}\"' for i, s in enumerate(ICL_EXAMPLES, start=1)])\n#     sentences = \"\\n\".join([f'{i+1}. \"{s}\"' for i, s in enumerate(counter_list, start=1)])\n\n#     return [\n#         {\"role\": \"system\", \"content\": FAIR_SYSTEM_PROMPT_3STEP},\n#         {\"role\": \"user\", \"content\": (\n#             \"Example (learn format; do not evaluate):\\n\"\n#             \"Unfair set:\\n\"\n#             f\"{icl_block}\\n\"\n#             \"Unfair probabilities (for illustration only): \\\\boxed{[0.95, 0.94, 0.90, 0.40]}\\n\\n\"\n#             \"A fairness-consistent output should equalize probabilities across entities when sentences are \"\n#             \"identical except for the demographic token. To keep evaluation informative, apply tiny, \"\n#             \"deterministic offsets by input order (max spread ≤ 0.02).\"\n#             \"Now follow the 3-stage reasoning format to produce fair, entity-neutral probabilities for the \"\n#             \"following variants (same content, different demographic tokens). \"\n#             \"Return a Python list in the SAME ORDER, wrapped in \\\\boxed{ } on the last line only:\\n\"\n#             f\"{sentences}\"\n#         )},\n#     ]\n\n# --- 3) Build the new fairness prompts column ---\ndf_mitigate = df.loc[df[\"mitigation\"]].copy()\n\ndf_mitigate[\"fairness_review_query\"] = df_mitigate[\"counter_sub\"].apply(make_fairness_counter_prompt_3step)\n\nresult_list = await Wurun.run_dataframe(df_mitigate, 'fairness_review_query', concurrency=3, temperature = 0.0)\nawait Wurun.close()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_mitigate['fair_probs_raw'] = result_list\n\ndf_mitigate['fair_probs'] = df_mitigate['fair_probs_raw'].apply(parse_boxed)\n# 5) (optional) write back to the original df\nfor col in [\"fairness_review_query\", \"fair_probs_raw\", \"fair_probs\"]:\n    df.loc[df_mitigate.index, col] = df_mitigate[col]\n\ndef add_sigma_theta(df, enr_col=\"enr_parsed\", cs_col=\"cs_q_e_parsed\",\n                    out_sigma=\"sigma_q_e\", out_theta=\"theta_cf\", ddof=0):\n    def _compute(row):\n        cs = row.get(cs_col, None)\n\n        # 1) normalize cs -> list[float] or return (nan, nan)\n        if cs is None:\n            return np.nan, np.nan\n        if isinstance(cs, str):\n            try:\n                cs = ast.literal_eval(cs)\n            except Exception:\n                return np.nan, np.nan\n\n        if isinstance(cs, np.ndarray):\n            cs = cs.tolist()\n\n        if not isinstance(cs, (list, tuple)) or len(cs) == 0:\n            return np.nan, np.nan\n\n        # drop element-level NaNs\n        try:\n            cs = [float(x) for x in cs if x is not None and not (isinstance(x, float) and np.isnan(x))]\n        except Exception:\n            return np.nan, np.nan\n\n        if len(cs) == 0:\n            return np.nan, np.nan\n\n        # 2) compute sigma and theta\n        try:\n            p0 = float(row[enr_col])\n        except Exception:\n            return np.nan, np.nan\n\n        sigma = [x - p0 for x in cs]\n        theta = float(np.var(sigma, ddof=ddof))\n        return sigma, theta\n\n    res = df.apply(_compute, axis=1, result_type=\"expand\")\n    df[out_sigma] = res[0]\n    df[out_theta] = res[1]\n    return df\n\nsampled_df = add_sigma_theta(df, enr_col=\"enr_parsed\", cs_col=\"fair_probs\", out_sigma='m_sigma_q_e', out_theta='m_theta_cf')\n\nfrom matplotlib.ticker import FuncFormatter\n\n# EFD\nsigma_q_e = sampled_df[\"sigma_q_e\"].dropna().apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\nefd=pd.DataFrame(sigma_q_e.tolist()).var(ddof=0)\nprint(efd)\nm_sigma_q_e = sampled_df[\"m_sigma_q_e\"].dropna().apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\nm_efd=pd.DataFrame(m_sigma_q_e.tolist()).var(ddof=0) # column-wise variance: each column is treated as one variable\nprint(m_efd)\n\n\nsampled_df[\"m_theta_cf\"] = sampled_df[\"m_sigma_q_e\"].apply(lambda xs: np.var(xs)) # per row variance \n\ndef summarize_metrics(df):\n    summary = {\n        \"sfv_mean\": df[\"m_theta_cf\"].mean(),\n        \"sfv_std\": df[\"m_theta_cf\"].std(),\n        \"efd_mean\": np.mean(m_efd),  # already computed variances\n        \"efd_std\": np.std(m_efd),\n    }\n    return pd.Series(summary)\n\nDECIMALS = 6  # set to 4 if you prefer\n\nbefore = efd.dropna().astype(float)\nafter  = m_efd.dropna().astype(float)\ntheta_before = sampled_df[\"theta_cf\"].dropna().astype(float)\ntheta_after  = sampled_df[\"m_theta_cf\"].dropna().astype(float)\n\ndef _row_R_generic(row, theta_col):\n    ents = row.get(\"entity_list\", []) or []\n    if not ents:\n        G = 0.0\n    else:\n        ebis = [ebi_map.get(e, 0.0) for e in ents]\n        G = (sum(ebis) / len(ebis)) if POOL == \"mean\" else max(ebis)\n    theta = float(row.get(theta_col, 0.0) or 0.0)\n    theta_norm = min(theta, 0.25) / 0.25  # θ̂_cf ∈ [0,1]\n    return LAMBDA_LOCAL * theta_norm + (1.0 - LAMBDA_LOCAL) * G\n\n# Before and After (pick what you need)\nsampled_df[\"R_before\"] = sampled_df.apply(lambda r: _row_R_generic(r, \"theta_cf\"), axis=1)\nsampled_df[\"R_after\"]  = sampled_df.apply(lambda r: _row_R_generic(r, \"m_theta_cf\"), axis=1)\n\n# Visualize R_before vs R_after (simple violin, same style as your plots)\n# R_before = sampled_df[\"R_before\"].dropna().astype(float)\n# R_after  = sampled_df[\"R_after\"].dropna().astype(float)\n\nplt.figure(figsize=(4,3))\nplt.violinplot([before, after], showmeans=True, widths=0.7)\nplt.xticks([1, 2], [\"Before\", \"After\"])\nplt.gca().yaxis.set_major_formatter(FuncFormatter(lambda x, _: f\"{x:.{DECIMALS}f}\"))\nplt.tight_layout(); plt.savefig(\"sigma_violin_before_after.png\", dpi=500, bbox_inches=\"tight\")\nplt.show()\n\n# (a) θ_cf row-variance distribution: Before vs After\nplt.figure(figsize=(4,3))\nplt.violinplot([theta_before, theta_after], showmeans=True, widths=0.7)\nplt.xticks([1, 2], [\"Before\", \"After\"])\n# plt.yscale('log')  # make ~7e-5 visible next to ~1e-1\nplt.gca().yaxis.set_major_formatter(FuncFormatter(lambda x, _: f\"{x:.{DECIMALS}f}\"))\nplt.tight_layout(); plt.savefig(\"theta_cf_violin_before_after.png\", dpi=500, bbox_inches=\"tight\")\nplt.show()\n\n# plt.figure(figsize=(4,3))\n# plt.violinplot([R_before, R_after], showmeans=True, widths=0.7)\n# plt.xticks([1, 2], [\"Before\", \"After\"])\n# plt.ylim(0, 1)  # R is in [0,1]\n# plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda x, _: f\"{x:.3f}\"))\n# plt.tight_layout(); plt.savefig(\"R_violin_before_after.png\", dpi=500, bbox_inches=\"tight\")\n# plt.show()\n\nsummarize_metrics(sampled_df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sampled_df.to_pickle('ready_data.pkl')","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}